{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minicons import scorer\n",
    "import pandas as pd\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model successfully loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\CS_programs\\Python\\LLM_Logic\\.env\\Lib\\site-packages\\minicons\\scorer.py:1231: UserWarning: tokenizer is changed by adding pad_token_id to the tokenizer.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  gpt2 = AutoModelForCausalLM.from_pretrained('gpt2-large', return_dict=True)\n",
    "  gpt2_tokenizer = AutoTokenizer.from_pretrained('gpt2-large', use_fast=True)\n",
    "  model = scorer.IncrementalLMScorer(gpt2, tokenizer=gpt2_tokenizer, device='cpu')\n",
    "  # model = scorer.IncrementalLMScorer('gpt2-large', 'cpu')\n",
    "  # model = scorer.IncrementalLMScorer('roberta-base', 'cpu')\n",
    "  # model = scorer.IncrementalLMScorer('xlnet-base-cased', 'cpu')\n",
    "  print(\"model successfully loaded.\")\n",
    "except Exception as e:\n",
    "    print(\"model loading error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 sets of stimuli in the given CSV file.\n"
     ]
    }
   ],
   "source": [
    "# CSV path (change accordingly)\n",
    "csv_path = \"lungu_scale_test.csv\" \n",
    "stimuli_list = []\n",
    "fields = ['Instructions', 'Condition', 'Study', 'Type', 'Proposition', 'NAND', 'NOR', 'Positive AND']  # Columns used in CSV\n",
    "row_order = 1\n",
    " \n",
    "# Reading CSV to dataframe\n",
    "stimuli_df = pd.read_csv(csv_path, usecols=fields)\n",
    "for _, row in stimuli_df.iterrows():\n",
    "    stimulis = {}\n",
    "\n",
    "    if (row['Condition'] == \"Control\"):\n",
    "        text_parts = [row['Instructions'], row['Proposition']]\n",
    "    \n",
    "    else:\n",
    "        # Getting continuations \n",
    "        conts = {\"NAND\":row[\"NAND\"], \"NOR\":row[\"NOR\"], \"Contradictory\":row[\"Positive AND\"]}\n",
    "\n",
    "        # Creating stimuli sequences\n",
    "        for key, value in conts.items():\n",
    "            text_parts = [row['Proposition'], value]\n",
    "            stimulis[key] = ' '.join(filter(None, text_parts))\n",
    "\n",
    "    # Other info about stimulus\n",
    "    stimulis[\"condition\"] = row['Condition']\n",
    "    stimulis[\"study\"] = row['Study']\n",
    "    stimulis[\"type\"] = row['Type']\n",
    "    stimulis[\"order\"] = row_order\n",
    "    row_order += 1\n",
    "    \n",
    "    stimuli_list.append(stimulis)\n",
    "\n",
    "random.shuffle(stimuli_list)\n",
    "\n",
    "print(f\"Found {len(stimuli_list)} sets of stimuli in the given CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I remember correctly, John doesn’t drink wine or beer.  I don’t know which.\n",
      "If I remember correctly, John doesn’t drink wine or beer.  The doctor has forbidden him alcohol.\n",
      "NAND: -3.990891933441162 NOR: -4.757718563079834\n",
      "First sequence makes more sense.\n",
      "John is upset. Clearly, he didn’t pass the semantics or the syntax exam.  I wonder which it was.\n",
      "John is upset. Clearly, he didn’t pass the semantics or the syntax exam.  And it wouldn’t be the first time he failed those classes.\n",
      "NAND: -5.196961879730225 NOR: -4.064774513244629\n",
      "Second sequence makes more sense.\n",
      "Few people took the appetizer or the dessert. I don’t remember which.\n",
      "Few people took the appetizer or the dessert. The main dish was already expensive.\n",
      "NAND: -4.566789627075195 NOR: -3.7595956325531006\n",
      "Second sequence makes more sense.\n",
      "Peter told me he needed to travel light. To judge by the small size of his bag, he was travelling without his computer or his movie camera.  I wonder which of the two he decided to give up.\n",
      "Peter told me he needed to travel light. To judge by the small size of his bag, he was travelling without his computer or his movie camera.  I am sure he was a lot happier without electronic devices.\n",
      "NAND: -3.583770275115967 NOR: -3.592984914779663\n",
      "First sequence makes more sense.\n",
      "My grandmother made these cookies without rum or cinnamon. I can’t remember which.\n",
      "My grandmother made these cookies without rum or cinnamon. Instead of those ingredients she added homemade brandy.\n",
      "NAND: -4.986001968383789 NOR: -4.286540985107422\n",
      "Second sequence makes more sense.\n",
      "Apparently, few people are able to recite back a sequence of twelve letters or twelve numbers. I don’t remember which.\n",
      "Apparently, few people are able to recite back a sequence of twelve letters or twelve numbers. The limit is usually ten.\n",
      "NAND: -4.429683685302734 NOR: -3.7345149517059326\n",
      "Second sequence makes more sense.\n",
      "Kate used to live without coffee or chocolate. I don't remember which.\n",
      "Kate used to live without coffee or chocolate. Now she cannot imagine her life without them.\n",
      "NAND: -3.842899799346924 NOR: -3.2528533935546875\n",
      "Second sequence makes more sense.\n",
      "It seems John has lived here for years without medical or house insurance. I don’t remember which one.\n",
      "It seems John has lived here for years without medical or house insurance. Only now has it occurred to him that he needs both of them.\n",
      "NAND: -4.849876403808594 NOR: -3.616981267929077\n",
      "Second sequence makes more sense.\n",
      "If I remember correctly, Mary didn’t invite John or Suzi to her birthday party. I don’t know which of them.\n",
      "If I remember correctly, Mary didn’t invite John or Suzi to her birthday party. She’s upset with both of them and doesn’t want to see them.\n",
      "NAND: -3.6853291988372803 NOR: -3.1471445560455322\n",
      "Second sequence makes more sense.\n",
      "It’s cold in this house. I bet you, John didn’t close the window or the back door.  I wonder which one of those two we’ll find open.\n",
      "It’s cold in this house. I bet you, John didn’t close the window or the back door.  Look, just as I said, both of them are wide open!\n",
      "NAND: -3.897282838821411 NOR: -4.051290512084961\n",
      "First sequence makes more sense.\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "NAND_lp = []\n",
    "NOR_lp = []\n",
    "\n",
    "# Scoring and comparing each set of sequences for stimuli in stimuli list\n",
    "for stimuli in stimuli_list:\n",
    "    print(stimuli['NAND'])\n",
    "    print(stimuli['NOR'])\n",
    "\n",
    "    sequences = [stimuli['NAND'],\n",
    "            stimuli['NOR']]\n",
    "\n",
    "    # use sequence_score with different reduction options: \n",
    "    # Sequence Surprisal - lambda x: -x.sum(0).item()\n",
    "    # Sequence Log-probability - lambda x: x.sum(0).item()\n",
    "    # Sequence Surprisal, normalized by number of tokens - lambda x: -x.mean(0).item()\n",
    "    # Sequence Log-probability, normalized by number of tokens - lambda x: x.mean(0).item()\n",
    "    # and so on...\n",
    "\n",
    "    # Calculate log-probabilities for each sequence\n",
    "    scores = model.sequence_score(sequences, reduction=lambda x: x.mean(0).item())\n",
    "\n",
    "    score1, score2 = scores  # Extract scores for each sequence\n",
    "\n",
    "    print(f\"NAND: {score1} NOR: {score2}\")\n",
    "    NAND_lp.append(score1)\n",
    "    NOR_lp.append(score2)\n",
    "\n",
    "\n",
    "    if score1 > score2:\n",
    "        print(\"First sequence makes more sense.\")\n",
    "        outputs.append('NAND')\n",
    "    else:\n",
    "        print(\"Second sequence makes more sense.\")\n",
    "        outputs.append('NOR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses saved to responses_logprob_gpt2large.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Stimuli Wide (NAND)\": [stimulis[\"NAND\"] for stimulis in stimuli_list], \n",
    "                   \"Stimuli Narrow (NOR)\": [stimulis[\"NOR\"] for stimulis in stimuli_list],\n",
    "                   \"Condition\": [stimulis[\"condition\"] for stimulis in stimuli_list],\n",
    "                   \"Study\": [stimulis[\"study\"] for stimulis in stimuli_list],\n",
    "                   \"Type\": [stimulis[\"type\"] for stimulis in stimuli_list],\n",
    "                   \"Original order\": [stimulis[\"order\"] for stimulis in stimuli_list],\n",
    "                   \"Wide Scope Logprob\": NAND_lp,\n",
    "                   \"Narrow Scope Logprob\": NOR_lp,\n",
    "                   \"Higher Logprob\": outputs})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv_path = \"responses_logprob_gpt2large.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Responses saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
