{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Determine the model: can be gpt-3.5-turbo or gpt-4\n",
    "model_name = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  api_key = \"INSERT KEY\" # Add API key\n",
    "  openai.api_key = api_key\n",
    "  print(\"API key successfully loaded.\")\n",
    "except:\n",
    "  print(\"No API key file found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 prompts in the given CSV file.\n",
      "Given the following sentence, option A is the best continuation. Is the previous sentence true or false? John is upset. Clearly, he didn’t pass the semantics or the syntax exam. A: I wonder which it was. B: And it wouldn’t be the first time he failed those classes.\n",
      "Given the following sentence, option A is the best continuation. Is the previous sentence true or false? If I remember correctly, Mary didn’t invite John or Suzi to her birthday party. A: I don’t know which of them. B: She’s upset with both of them and doesn’t want to see them.\n",
      "Given the following sentence, option A is the best continuation. Is the previous sentence true or false? It’s cold in this house. I bet you, John didn’t close the window or the back door. A: I wonder which one of those two we’ll find open. B: Look, just as I said, both of them are wide open!\n",
      "Given the following sentence, option A is the best continuation. Is the previous sentence true or false? If I remember correctly, John doesn’t drink wine or beer. A: I don’t know which. B: The doctor has forbidden him alcohol.\n",
      "Given the following sentence, option A is the best continuation. Is the previous sentence true or false? I remember there was a family conflict. Mary didn’t speak with her mother or her sister. A: I don’t know which. B: She was only talking with her father after that.\n"
     ]
    }
   ],
   "source": [
    "# CSV path (change accordingly)\n",
    "csv_path = \"test_TF.csv\" \n",
    "prompts = []\n",
    "fields = ['Instructions', 'Condition', 'Study', 'Proposition', 'NAND', 'NOR']  # Columns used in CSV\n",
    "\n",
    "# Reading CSV to dataframe\n",
    "prompts_df = pd.read_csv(csv_path, usecols=fields)\n",
    "\n",
    "for _, row in prompts_df.iterrows():\n",
    "    prompt = {}\n",
    "\n",
    "    # Check if either \"A\" or \"B\" exists in the row\n",
    "    choices = {\"NAND\":row[\"NAND\"], \"NOR\":row[\"NOR\"]}\n",
    "    \n",
    "    text_parts = [row['Instructions'], row['Proposition'], \"A:\", row[\"NAND\"], \"B:\",row[\"NOR\"]]\n",
    "    \n",
    "    # Filter out empty strings before joining\n",
    "    prompt[\"text\"] = ' '.join(filter(None, text_parts))\n",
    "    prompt[\"condition\"] = row['Condition']\n",
    "    prompt[\"study\"] = row['Study']\n",
    "    \n",
    "    prompts.append(prompt)\n",
    "\n",
    "random.shuffle(prompts)\n",
    "\n",
    "print(f\"Found {len(prompts)} prompts in the given CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages generated with 481 tokens\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "total_tokens = 0\n",
    "\n",
    "# Calling chatGPT and appending responses to outputs list\n",
    "for prompt in prompts:\n",
    "  response = openai.ChatCompletion.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                      {\"role\": \"system\", \"content\": \"If prompted with a true or false question, only respond with either 'true' or 'false' in lowercase.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt[\"text\"]},\n",
    "                  ]\n",
    "              )\n",
    "  gpt_answer = response['choices'][0]['message']['content']\n",
    "  outputs.append(gpt_answer)\n",
    "\n",
    "  total_tokens += response[\"usage\"][\"total_tokens\"]\n",
    "\n",
    "print(f\"Messages generated with {total_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses saved to output_responses_TF.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Prompt\": [prompt[\"text\"] for prompt in prompts],  \n",
    "                   \"Condition\": [prompt[\"condition\"] for prompt in prompts],\n",
    "                   \"Study\": [prompt[\"study\"] for prompt in prompts],\n",
    "                   \"Response\": outputs})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv_path = \"output_responses_TF.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Responses saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
